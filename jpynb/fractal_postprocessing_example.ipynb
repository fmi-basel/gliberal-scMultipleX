{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67ce5cc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import zscore\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "from scmultiplex.plotting.functions_io import (zarr_wellpaths, \n",
    "                          append_table_to_zarr_url, \n",
    "                          load_features_for_well, \n",
    "                          make_anndata, \n",
    "                          invert_conditions_dict,\n",
    "                          make_object_dict,\n",
    "                          randomize_object_dict,\n",
    "                          load_imgs_from_object_dict,\n",
    "                          make_filtered_dict, import_conditions_csv)\n",
    "\n",
    "from scmultiplex.plotting.functions_plotting import (plot_heatmap, build_heatmap_df, plot_heatmap_means, plot_image_grid, \n",
    "                                plot_rgb_grid, plot_single_image, plot_single_rgb,  plot_pos_and_neg_sets, \n",
    "                                count_positive_fraction, plot_positive_fraction, plot_feature_violin)\n",
    "\n",
    "\n",
    "from scmultiplex.plotting.functions_classify import classify_me\n",
    "\n",
    "pd.set_option(\"display.max_columns\", 100)\n",
    "\n",
    "print(plt.style.available)\n",
    "plt.style.use('dark_background')\n",
    "plt.style.use('dark_background')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76c37bb0",
   "metadata": {},
   "source": [
    "# USER INPUT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f920f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set path to experiment \n",
    "# exp_path = 'path/to/folder/containing/plates'\n",
    "from configpath import exp_path\n",
    "print('Experiment path: %s' % exp_path)\n",
    "\n",
    "# set object_segmentation True if you have run object segmentation and would like to load object images. If False, load well overviews\n",
    "# set classify True if you would like to apply a trained classifier to a feature column. If False, no classification performed\n",
    "object_segmentation = False\n",
    "classify = False\n",
    "\n",
    "\n",
    "if object_segmentation:\n",
    "    feat_table_name = \"org_feat_table\" # name of feature extraction table, as specified in Fractal run\n",
    "    roi_name = \"org_ROI_table\" # name of object segmentation table\n",
    "    print('Read segmented object ROIs for table %s and corresponding features in table %s and visualize object images' % (roi_name, feat_table_name))\n",
    "else:\n",
    "    roi_name = \"well_ROI_table\" # name of well ROI table\n",
    "    print('Read well ROIs for table %s and visualize well overviews' % roi_name)\n",
    "    \n",
    "if classify:\n",
    "    # classifier_path = 'path/to/classifer/file/.clf'\n",
    "    from configpath import classifier_path\n",
    "    print('Classifier path: %s' % classifier_path)\n",
    "\n",
    "\n",
    "\n",
    "select_mip = True # select True if want to visualize MIP zarr; note only tested on this\n",
    "make_zarr_url = True # select True to select multiplexing round 0; TODO: if want to select other round, need to modify zarr_wellpaths function\n",
    "save_features_as_h5ad = False # select True if want to save aggregated feature table as anndata (h5ad) in experiment folder directory\n",
    "plate_size = 18 # integer, set plate format of experiment (e.g. 18, 24, 96, 384). \n",
    "# TODO: need to refactor import_conditions_csv if other plate formats are used, and consider changing to str input\n",
    "separate_by_plate_id = False # parameter for import_conditions_csv; if True condition names are 'plateid.cond'; if False names are 'cond' where cond is the name given in csv file and plateid is the name of the plate\n",
    "n_obj = 6 # number of objects to display per condition (i.e. number of columns in image grid)\n",
    "seed = 4 # seed for random sampling of objects\n",
    "level = 1 # zarr level of image to be loaded (0 is full resolution); can also change manually for each plotting function\n",
    "\n",
    "husl = sns.color_palette(\"husl\", 9).as_hex()[0:8] # set palette and number of colors to use for discrete color scale (for violin and jitter plots)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a82f5cc4",
   "metadata": {},
   "source": [
    "# END USER INPUT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ed05534",
   "metadata": {},
   "source": [
    "## Aggregate data from all plates and wells in experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9660738",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if object_segmentation: \n",
    "    # extract plate and well info for objects from feature table\n",
    "    table_name = feat_table_name\n",
    "else:\n",
    "    # extract plate and well info for well overviews from well ROI table\n",
    "    table_name = roi_name\n",
    "    \n",
    "df = pd.DataFrame()\n",
    "\n",
    "# zarr_url_dict key: tuple(plate, well), value: path to well (round 0) \n",
    "zarr_url_dict, plate_ids, well_ids, row_ids, col_ids = zarr_wellpaths(exp_path, select_mip = select_mip, make_zarr_url = make_zarr_url)\n",
    "# zarr_url_tables_dict key: tuple(plate, well), value: path to feature or well ROI table\n",
    "zarr_url_tables_dict = append_table_to_zarr_url(zarr_url_dict, table_name)\n",
    "\n",
    "# loop over each imaged well\n",
    "for key in zarr_url_tables_dict:\n",
    "    path = zarr_url_tables_dict[key]\n",
    "    \n",
    "    if os.path.exists(path):\n",
    "        df_well = load_features_for_well(path)\n",
    "        if df_well is not None:\n",
    "            df_well[\"plate_id\"] = plate_ids[key]\n",
    "            df_well[\"well_id\"] = well_ids[key]\n",
    "            df_well[\"row_id\"] = row_ids[key]\n",
    "            df_well[\"col_id\"] = col_ids[key]\n",
    "            df = pd.concat([df_well, df])\n",
    "    else:\n",
    "        warnings.warn('no table rows detected in (plate, well) %s' % key)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "453a28ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "if object_segmentation: \n",
    "    print('detected ', df.shape[0], ' organoids and ', df.shape[1], ' feature columns')\n",
    "else:\n",
    "    print('detected ', df.shape[0], ' wells in experiment')\n",
    "\n",
    "df.head(5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "617fc9d7",
   "metadata": {},
   "source": [
    "## Run classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f5cb487",
   "metadata": {},
   "outputs": [],
   "source": [
    "if classify:\n",
    "    #df = df.reset_index(drop=True)\n",
    "    df['roi_id'] = df[\"plate_id\"] + \"_\" + df[\"well_id\"] + \"_\" + df[\"label\"].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b16b392",
   "metadata": {},
   "outputs": [],
   "source": [
    "if classify:\n",
    "    df_predicted, new_prediction, class_names = classify_me(df, classifier_path, 'roi_id')\n",
    "    df_predicted"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b94a2d35",
   "metadata": {},
   "source": [
    "## Convert aggregated organoid df into AnnData object and save as H5AD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cecb065",
   "metadata": {},
   "outputs": [],
   "source": [
    "if save_features_as_h5ad:\n",
    "    # create unique organoid index for each row\n",
    "    df['oUID'] = df[\"plate_id\"] + \"_\" + df[\"well_id\"] + \"_\" + df[\"label\"].astype(str)\n",
    "    df['oUID_tuple'] = list(zip(df.plate_id, df.well_id, df.label.astype(str)))\n",
    "    df = df.set_index('oUID')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "928a3115",
   "metadata": {},
   "outputs": [],
   "source": [
    "if save_features_as_h5ad:\n",
    "    # select numeric features to be saved in anndata X: note may be user-specific\n",
    "    org_numerics_list = ['x_pos_pix', 'y_pos_pix', 'imgdim_x', 'imgdim_y', \n",
    "                         'mean_intensity', 'max_intensity', 'min_intensity', \n",
    "                         'percentile25', 'percentile50', 'percentile75', 'percentile90', 'percentile95', 'percentile99',\n",
    "                         'stdev', 'skew', 'kurtosis',\n",
    "                         'x_pos_weighted_pix', 'y_pos_weighted_pix', 'x_massDisp_pix', 'y_massDisp_pix',\n",
    "                         'area_bbox', 'area_convhull', 'equivDiam', 'extent', 'solidity',\n",
    "                         'majorAxisLength', 'minorAxisLength', 'minmajAxisRatio', \n",
    "                         'aspectRatio_equivalentDiameter', 'area_pix', 'perimeter', 'concavity', \n",
    "                         'asymmetry', 'eccentricity', 'circularity', 'concavity_count'\n",
    "                         ]\n",
    "    # select object properties to be saved in anndata obs: note may be user-specific\n",
    "    org_obs_list = [\"label\", \"ROI_table_name\", \"ROI_name\", \"index\", \n",
    "                    \"is_touching_border_xy\", \"disconnected_components\", \n",
    "                    \"plate_id\", \"well_id\", \"col_id\", \"row_id\"]\n",
    "    \n",
    "    adata = make_anndata(df, org_numerics_list, org_obs_list)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efd54b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "if save_features_as_h5ad:\n",
    "    # save anndata in exp_path as h5ad file\n",
    "    adata.write(filename = os.path.join(exp_path, 'org.h5ad'))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2440ad6b",
   "metadata": {},
   "source": [
    "## Visualize images prior to filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43d6254e",
   "metadata": {},
   "source": [
    "# USER INPUT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5248afb4",
   "metadata": {},
   "source": [
    "## Make conditions table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de2fab97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# key is already in zarr_url_dict in format tuple(plate_id, well_id)\n",
    "print('example of key: ')\n",
    "list(zarr_url_dict.keys())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5666654c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "for each well (key), set a condition name (value). condition names can repeat.\n",
    "format must be\n",
    "unique well id : condition id\n",
    "\n",
    "example:\n",
    "\n",
    "for plate layout where condition replicates are along columns:\n",
    "conditions = {key: plate_ids[key][-5:] + \".\" + col_ids.get(key, '') for key in zarr_url_dict.keys()}\n",
    "\n",
    "or use csv file located in exp_path with same name as plate, csv for each plate:\n",
    "conditions = import_conditions_csv(zarr_url_dict, exp_path, plate_size = 18)\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "conditions = import_conditions_csv(zarr_url_dict, exp_path, plate_size = plate_size, separate_by_plate_id=separate_by_plate_id)\n",
    "conditions"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5440851c7429455d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdb9df99",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Set condition as column in DF, and add timepoint column (if applicable, can also be set to equal plate_id)\n",
    "df['wUID_tuple'] = list(zip(df.plate_id, df.well_id))\n",
    "df['condition'] = df['wUID_tuple'].map(conditions)\n",
    "\n",
    "# add timepoint column to dataframe; might need to modify parsing!\n",
    "df[\"timepoint\"] = df['plate_id']\n",
    "# df[\"timepoint\"] = df['plate_id'].str.split('-', 2, expand=True)[1]\n",
    "\n",
    "print(\"Check that condition (mandatory) and timepoint (optional) columns are correct!\")\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be706e04",
   "metadata": {},
   "source": [
    "# END USER INPUT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "822c423f",
   "metadata": {},
   "outputs": [],
   "source": [
    "inv_cond = invert_conditions_dict(conditions)\n",
    "\n",
    "objects_to_randomize = make_object_dict(inv_cond, zarr_url_dict, roi_name)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1386594e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if object_segmentation: \n",
    "    objects_randomized = randomize_object_dict(objects_to_randomize, n_obj = n_obj, seed = seed)\n",
    "    objects_randomized\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62dbf097",
   "metadata": {},
   "outputs": [],
   "source": [
    "# note user much check channel indeces below and load relevant channels in dataset\n",
    "#TODO: read channels automatically from zarr metadata \n",
    "\n",
    "if object_segmentation: \n",
    "    plot_me = objects_randomized\n",
    "else:\n",
    "    plot_me = objects_to_randomize\n",
    "\n",
    "# load random image set\n",
    "# reset_origin if False, origin is set to 0,0,0 ; if True, origin is calculated from minimum pixel coordinates of image\n",
    "\n",
    "c0_all_dict = load_imgs_from_object_dict(plot_me,\n",
    "                                            zarr_url_dict,\n",
    "                                            channel_index = 0,\n",
    "                                            level=level,\n",
    "                                            roi_name = roi_name, \n",
    "                                            reset_origin=False)\n",
    "\n",
    "c1_all_dict = load_imgs_from_object_dict(plot_me,\n",
    "                                            zarr_url_dict,\n",
    "                                            channel_index = 1,\n",
    "                                            level=level,\n",
    "                                            roi_name = roi_name, \n",
    "                                            reset_origin=False)\n",
    "\n",
    "c2_all_dict = load_imgs_from_object_dict(plot_me,\n",
    "                                            zarr_url_dict,\n",
    "                                            channel_index = 2,\n",
    "                                            level=level,\n",
    "                                            roi_name = roi_name, \n",
    "                                            reset_origin=False)\n",
    "\n",
    "# c3_all_dict = load_imgs_from_object_dict(plot_me,\n",
    "#                                             zarr_url_dict,\n",
    "#                                             channel_index = 3,\n",
    "#                                             level=level,\n",
    "#                                             roi_name = roi_name, \n",
    "#                                             reset_origin=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f06bc892",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "plot image grid, single channel at a time\n",
    "each image is padded to largest image dimension in set, so that zoom of images are equal and comparable across conditions\n",
    "intensity scale is normalized to max of each image so images are not comparable in intensity. TODO: add global scaling as option\n",
    "    # brighten: scalar to increase or decrease scaling, i.e. brighten * np.amax(img)\n",
    "    # cmap: color map \n",
    "'''\n",
    "\n",
    "plot_image_grid(c0_all_dict, brighten=0.5, cmap='gray')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1663aa94",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_single_image(c0_all_dict, cond = '144', plate_id = 'dirconjpbsce3140144_slide2_out', well_id = 'C05', org_id = 'well_1')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7155029b",
   "metadata": {},
   "source": [
    "## Visualize RGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d3ae28a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "plot image grid of RGBs. note must have 3 channels; TODO: support two-channel input\n",
    "first three arguments are image dictionaries passed in order r, g, b \n",
    "each image is padded to largest image dimension in set, so that zoom of images are equal and comparable across conditions\n",
    "intensity scale is normalized based on parameters:\n",
    "    # min_quantile: float range 0 to 1 to set minimum quantile cutoff for intensity rescale (e.g. 0.05 means that lowest 5% of pixels will be set to 0)\n",
    "    # max_quantile: float range 0 to 1 to set maximum quantile cutoff for intensity rescale (e.g. 0.99 means that 1% of pixels will be saturated)\n",
    "    # global_norm: True means that each channel across images will be rescaled to the same intensity cutoff, set by the min_ and max_quantile of all images in set for a given channel (default) or by manually specified ranges (see ranges parameter), so intensities for a given channel are comparable across all conditions. False means each image and channel is individually rescaled to its min_ and max_quantile value. \n",
    "    # ranges: Alternative to auto-scaling during global normalization. User can manually specify scaling range for each channel (r,g,b) as a tuple of tuples, e.g. ranges = ((0.0, 14707.5),(0.0, 1559.5),(0.0, 8673.0)) and in this case quantile values are ignored. Set ranges = () to use quantile scaling default of global_norm when global_norm = True. This parameter is ignored if global_norm = False. \n",
    "'''\n",
    "\n",
    "plot_rgb_grid(r_dict = c2_all_dict, g_dict = c1_all_dict, b_dict = c0_all_dict, min_quantile = 0.1, max_quantile = 0.99,\n",
    "             global_norm = False, ranges = ())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d015ffba",
   "metadata": {},
   "source": [
    "## NOTE: Subsequent sections only run for object features (object_segmentation = True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78126dd8",
   "metadata": {},
   "source": [
    "## Heatmap plate visualization: number of organoids per plate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "862eb731",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: add as plotting function to functions_plotting\n",
    "\n",
    "for plate in np.unique(df['plate_id']):\n",
    "    df_hm = build_heatmap_df(plate_size = 96)\n",
    "    df_plt = df[(df.plate_id == plate)].copy(deep = True)\n",
    "    df_plt['count'] = 1\n",
    "    grouped = df_plt.groupby([\"well_id\"])['count'].count().to_frame()\n",
    "    \n",
    "    for well in grouped.index:\n",
    "        df_hm.loc[well[0], well[1:]] = grouped.loc[well]['count']\n",
    "    \n",
    "    vmin = min(df_hm.min().dropna())\n",
    "    vmax = max(df_hm.max().dropna())\n",
    "    hm = plot_heatmap(df_hm, 'viridis', annot = True, vmin = vmin, vmax = vmax)\n",
    "    \n",
    "    hm.set_title(plate + \"\\n\", loc = 'left')\n",
    "    plt.subplots_adjust(top = 0.6)\n",
    "                \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad89eb46",
   "metadata": {},
   "source": [
    "## Jitterplot visualization: organoid features per timepoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0e1de4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize= (16,10))\n",
    "\n",
    "\n",
    "plt.subplot(2, 3, 1)\n",
    "cx = sns.stripplot(x=\"timepoint\", y=\"area_pix\", data=df, size=3, palette = husl)\n",
    "plt.title(\"area_pix\", fontsize=12)\n",
    "\n",
    "plt.subplot(2, 3, 2)\n",
    "cx = sns.stripplot(x=\"timepoint\", y=\"circularity\", data=df, size=3, palette = husl)\n",
    "plt.title(\"circularity\", fontsize=12)\n",
    "\n",
    "plt.subplot(2, 3, 3)\n",
    "cx = sns.stripplot(x=\"timepoint\", y=\"disconnected_components\", data=df, size=3, palette = husl)\n",
    "plt.title(\"disconnected_components\", fontsize=12)\n",
    "\n",
    "plt.subplot(2, 3, 4)\n",
    "cx = sns.stripplot(x=\"timepoint\", y=\"C01.mean_intensity\", data=df, size=3, palette = husl)\n",
    "plt.title(\"C01.mean_intensity\", fontsize=12)\n",
    "\n",
    "plt.subplot(2, 3, 5)\n",
    "cx = sns.stripplot(x=\"timepoint\", y=\"is_touching_border_xy\", data=df, size=3, palette = husl)\n",
    "plt.title(\"is_touching_border_xy\", fontsize=12)\n",
    "\n",
    "plt.subplot(2, 3, 6)\n",
    "cx = sns.stripplot(x=\"timepoint\", y=\"C02.mean_intensity\", data=df, size=3, palette = husl)\n",
    "plt.title(\"C02.mean_intensity\", fontsize=12)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0e3e518",
   "metadata": {},
   "source": [
    "## Filter organoids by features, per timepoint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6552e654",
   "metadata": {},
   "source": [
    "# USER INPUT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f901ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_filt = ['area_pix','circularity', 'C01.mean_intensity']\n",
    "\n",
    "#initialize dictionary for storing desired quantiles\n",
    "q = {} \n",
    "for tp in df[\"timepoint\"].unique():\n",
    "    q[tp] = {}\n",
    "    for feat in features_filt:\n",
    "        if feat == 'area_pix':\n",
    "            q[tp][feat] = [0.01, 0.999] \n",
    "        elif feat == 'circularity':\n",
    "            if tp == 'd5':\n",
    "                q[tp][feat] = [0., 0.85] # remove objects with high circularity at later tps\n",
    "            else:\n",
    "                q[tp][feat] = [0., 1.]\n",
    "        elif feat == 'C01.mean_intensity':\n",
    "            q[tp][feat] = [0.02, 1.0] \n",
    "        else: \n",
    "            q[tp][feat] = [0.05, 1.0]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c37df59",
   "metadata": {},
   "source": [
    "# END USER INPUT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bffbb806",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "##Calculate z-score by plate or timepoint\n",
    "for feat in features_filt:\n",
    "    df[feat+\"_z\"] = df.groupby([\"timepoint\"])[feat].transform(lambda x : zscore(x,ddof=0))\n",
    "\n",
    "##Filter based on z_score \n",
    "df_filtered = pd.DataFrame()\n",
    "org_to_omit_q = []\n",
    "\n",
    "inv_tp = {}\n",
    "\n",
    "for tp in df[\"timepoint\"].unique():\n",
    "    df_tp = df.loc[(df[\"timepoint\"] == tp)]\n",
    "    for feat in features_filt:\n",
    "        tp_org_to_omit_q=[]\n",
    "        #quantile based on dictionary value specified above, unique quantile for each tp and filter\n",
    "        qval1=np.quantile(df_tp[feat+\"_z\"],q[tp][feat][0])\n",
    "        qval2=np.quantile(df_tp[feat+\"_z\"],q[tp][feat][1])\n",
    "        #save qval in quantile dictionary for plotting\n",
    "        q[tp][feat].append(qval1)\n",
    "        q[tp][feat].append(qval2)\n",
    "        temp_removed = df_tp.loc[(df_tp[feat+\"_z\"]<qval1) | (df_tp[feat+\"_z\"]>qval2)]\n",
    "        \n",
    "        org_to_omit_q.append(temp_removed[\"oUID_tuple\"].unique())\n",
    "        tp_org_to_omit_q.append(temp_removed[\"oUID_tuple\"].unique())\n",
    "\n",
    "        tp_org_to_omit_q= np.unique(np.concatenate(tp_org_to_omit_q))\n",
    "        # add to dictionary\n",
    "        inv_tp[tp + \"_\" + feat] = tp_org_to_omit_q\n",
    "    \n",
    "        \n",
    "        print(\"Omitted\", len(temp_removed[\"oUID_tuple\"].unique()), \"organoids based on\", feat, \"in timepoint\", tp)\n",
    "\n",
    "\n",
    "#List of organoids to remove\n",
    "org_to_omit_q = np.unique(np.concatenate(org_to_omit_q))\n",
    "\n",
    "df_r = df[df[\"oUID_tuple\"].isin(org_to_omit_q)] #dataframe of removed organoids\n",
    "#display(df1_r)\n",
    "\n",
    "#print(\"These \", len(org_to_omit_q), \"organoid_IDs have been removed during quantile filter:\", org_to_omit_q)\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18b4ff23",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Plot histograms of features and cutoffs \n",
    "for feat in features_filt:\n",
    "    #graph histogram\n",
    "    plt.figure(figsize=(9,6))\n",
    "    sns.swarmplot(x=\"timepoint\", y=feat+\"_z\", data=df, size =3, palette = husl)\n",
    "    plt.title(feat+\"_z\", fontsize=12)\n",
    "    \n",
    "    for n,tp in enumerate(df[\"timepoint\"].unique()):\n",
    "        m = len(df[\"timepoint\"].unique())\n",
    "        plt.axhline(q[tp][feat][2], xmin=(n/m+(0.1/m)), xmax=(n/m+(0.9/m)), color = 'r')\n",
    "        plt.axhline(q[tp][feat][3], xmin=(n/m+(0.1/m)), xmax=(n/m+(0.9/m)), color = 'r')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d103c3f4",
   "metadata": {},
   "source": [
    "## Plot removed organoids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48278ed2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "objects_randomized = randomize_object_dict(inv_tp, n_obj = 6, seed = 3)\n",
    "#objects_randomized\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ff2e397",
   "metadata": {},
   "outputs": [],
   "source": [
    "filt_npimg_dict = load_imgs_from_object_dict(objects_randomized,\n",
    "                                            zarr_url_dict,\n",
    "                                            channel_index = 0,\n",
    "                                            level=0,\n",
    "                                            roi_name = roi_name, \n",
    "                                            reset_origin=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04472124",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_image_grid(filt_npimg_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e284a5d",
   "metadata": {},
   "source": [
    "## Remove organoids from source and plot cleaned-up dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8f658a4",
   "metadata": {},
   "source": [
    "# USER INPUT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de283b38",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Remove organoids that are in removal list\n",
    "df_filtered = df.drop(df[df[\"oUID_tuple\"].isin(org_to_omit_q)].index)\n",
    "\n",
    "\n",
    "\n",
    "# remove organoids that are positive for these:           \n",
    "df_filtered.drop(df_filtered[df_filtered['disconnected_components'] == 1.0].index, inplace = True)\n",
    "df_filtered.drop(df_filtered[df_filtered['is_touching_border_xy'] == 1.0].index, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "608c29b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop any unwanted conditions (only from DF, not from image plotting objects!)\n",
    "#df_filtered.drop(df_filtered[df_filtered['condition'] == \"d5-P2.05\"].index, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdc9b253",
   "metadata": {},
   "source": [
    "# END USER INPUT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29534ee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove from filtered organoids plotting dictionary\n",
    "all_objects = make_object_dict(inv_cond, zarr_url_dict, roi_name)\n",
    "\n",
    "objects_filtered = make_filtered_dict(all_objects, org_to_omit_q, omit_my_list = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "854d725c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# randomize and load images\n",
    "\n",
    "objects_randomized = randomize_object_dict(objects_filtered, n_obj = 6, seed = 9)\n",
    "\n",
    "c01_filt_dict = load_imgs_from_object_dict(objects_randomized,\n",
    "                                            zarr_url_dict,\n",
    "                                            channel_index = 0,\n",
    "                                            level=1,\n",
    "                                            roi_name = roi_name, \n",
    "                                            reset_origin=False)\n",
    "\n",
    "c02_filt_dict = load_imgs_from_object_dict(objects_randomized,\n",
    "                                            zarr_url_dict,\n",
    "                                            channel_index = 1,\n",
    "                                            level=1,\n",
    "                                            roi_name = roi_name, \n",
    "                                            reset_origin=False)\n",
    "\n",
    "c03_filt_dict = load_imgs_from_object_dict(objects_randomized,\n",
    "                                            zarr_url_dict,\n",
    "                                            channel_index = 2,\n",
    "                                            level=1,\n",
    "                                            roi_name = roi_name, \n",
    "                                            reset_origin=False)\n",
    "c04_filt_dict = load_imgs_from_object_dict(objects_randomized,\n",
    "                                            zarr_url_dict,\n",
    "                                            channel_index = 3,\n",
    "                                            level=1,\n",
    "                                            roi_name = roi_name, \n",
    "                                            reset_origin=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd55f329",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_rgb_grid(c03_filt_dict, c02_filt_dict, c01_filt_dict, ncols=None, min_quantile = 0, max_quantile = 0.9,\n",
    "                      global_norm = True, auto_range = True, ranges = ())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64b8fb86",
   "metadata": {},
   "outputs": [],
   "source": [
    "c03_filt_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d5a410f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_single_rgb(c03_filt_dict, c02_filt_dict, c01_filt_dict, cond = 'd3-P1.02', \n",
    "                plate_id = '20230712-d3-P1', well_id = 'C02', org_id = '56')\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18dc62a5",
   "metadata": {},
   "source": [
    "## Plot organoid-level feature data across conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "120896d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef01552c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_heatmap_means(df_filtered, feature = 'C03.mean_intensity', plate_size = 96, vmax_multiplier=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ea115c2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_feature_violin(df_filtered, colname = 'C03.mean_intensity')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e71c9912",
   "metadata": {},
   "source": [
    "## Filter positive/negative organoids with threshold cutoff and plot "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdaa3e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered, grouped = count_positive_fraction(df_filtered, colname = 'C03.mean_intensity', thresh = 2000)\n",
    "plot_positive_fraction(grouped)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6b7096e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_pos_and_neg_sets(df_filtered, grouped, inv_cond, \n",
    "                          zarr_url_dict, roi_name, n_obj=6, seed=3, level=1, \n",
    "                          min_quantile=0, max_quantile=0.88,\n",
    "                          r_ch_idx =2, g_ch_idx=1, b_ch_idx=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3060889b",
   "metadata": {},
   "source": [
    "## Repeat with another marker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9a49ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_heatmap_means(df_filtered, feature = 'C02.max_intensity', plate_size = 96, vmax_multiplier=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50da2289",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_filtered['C02.sum_intensity'] = df_filtered['area_pix'] * df_filtered['C02.mean_intensity']\n",
    "plot_feature_violin(df_filtered, colname = 'C02.max_intensity') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c17e8621",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered, grouped = count_positive_fraction(df_filtered, colname = 'C02.max_intensity', thresh = 5000)\n",
    "\n",
    "plot_positive_fraction(grouped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "956080a1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_pos_and_neg_sets(df_filtered, grouped, inv_cond, \n",
    "                          zarr_url_dict, roi_name, n_obj=6, seed=2, level=1, \n",
    "                          min_quantile=0, max_quantile=0.88,\n",
    "                          r_ch_idx =2, g_ch_idx=1, b_ch_idx=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8138c70b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered['area_diff'] = df_filtered['area_convhull'] - df_filtered['area_pix']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20cb0927",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_feature_violin(df_filtered, colname = 'area_diff')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65314d62",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
